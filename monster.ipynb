{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd102cb9-7f4c-4bf4-9f5e-6689ac1145b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gprm import ReconstructionModel\n",
    "import pygmt\n",
    "import geopandas as gpd\n",
    "import sys\n",
    "sys.path.append('/Users/simon/GIT/degenerative_art/')\n",
    "import map_effects as me\n",
    "sys.path.append('/Users/simon/GIT/agegrid-0.1/')\n",
    "from run_paleo_age_grids import run_paleo_age_grids\n",
    "import xarray as xr\n",
    "from xrspatial import proximity\n",
    "import gprm.utils.paleogeography as pg\n",
    "import pygplates\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298d94ea-2d5f-4e4e-8e51-702c1e0f9560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Atlantis = ReconstructionModel()\n",
    "\n",
    "Atlantis.add_continent_polygons('/Users/simon/Documents/2022IMAS-OUC_SOMG/PracFiles/Atlantis2/Atlantis2_continents.gpml')\n",
    "Atlantis.add_dynamic_polygons('/Users/simon/Documents/2022IMAS-OUC_SOMG/PracFiles/Atlantis2/Atlantis2_topologies.gpml')\n",
    "Atlantis.add_dynamic_polygons('/Users/simon/Documents/2022IMAS-OUC_SOMG/PracFiles/Atlantis2/Atlantis2_geometries.gpml')\n",
    "Atlantis.add_rotation_model('/Users/simon/Documents/2022IMAS-OUC_SOMG/PracFiles/Atlantis2/Atlantis2_rotations.rot')\n",
    "\n",
    "final_grd_sampling = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a2a642-3e14-425e-9fdc-184fde291328",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 1 run paleoagegrid\n",
    "\n",
    "#run_paleo_age_grids('/Users/simon/GIT/agegrid-0.1/config_files/config_Atlantis.yaml')\n",
    "seafloor_age = pygmt.grdsample('./Atlantis2/masked/Atlantis2_seafloor_age_mask_0.0Ma.nc',\n",
    "                               region='d', spacing='{:f}d'.format(final_grd_sampling)) #xr.load_dataarray('./Atlantis2/masked/Atlantis2_seafloor_age_mask_0.0Ma.nc')\n",
    "\n",
    "seafloor_depth = seafloor_age.copy(deep=True)\n",
    "seafloor_depth.data = pg.age2depth(seafloor_depth.data, model='GDH1')\n",
    "\n",
    "seafloor_depth.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d38a1a-beb0-4a9c-aba3-47d5f987e885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 2 run make mountain ranges\n",
    "\n",
    "reconstruction_model = Atlantis\n",
    "reconstruction_time = 0.\n",
    "min_distance_to_coastlines=0\n",
    "max_distance_to_trenches=1200000\n",
    "sampling = final_grd_sampling\n",
    "\n",
    "\n",
    "rp = me.reconstruct_and_rasterize_polygons(reconstruction_model.continent_polygons[0], \n",
    "                                           reconstruction_model.rotation_model, \n",
    "                                           reconstruction_time=reconstruction_time, \n",
    "                                           sampling=sampling)\n",
    "\n",
    "_, prox_ocean = me.raster_buffer(rp, inside='both')\n",
    "\n",
    "# Get subduction zones, and compute a raster of distances to the nearest one\n",
    "snapshot = reconstruction_model.plate_snapshot(reconstruction_time)\n",
    "\n",
    "szs = snapshot.get_boundary_features(boundary_types=['subduction'])\n",
    "all_sz_points = []\n",
    "for sz in szs:\n",
    "    if sz.get_geometry():\n",
    "        all_sz_points.extend(sz.get_geometry().to_tessellated(np.radians(0.1)).to_lat_lon_list())\n",
    "\n",
    "prox_sz = me.points_proximity(x=[lon for lat,lon in all_sz_points],\n",
    "                              y=[lat for lat,lon in all_sz_points],\n",
    "                              spacing=sampling)\n",
    "\n",
    "# Orogeny Points\n",
    "orogeny_points = []\n",
    "pygplates.reconstruct('/Users/simon/Documents/2022IMAS-OUC_SOMG/PracFiles/Atlantis2/Atlantis2_OrogenicBelts.gpml', \n",
    "                      Atlantis.rotation_model, orogeny_points, reconstruction_time)\n",
    "all_op_points = []\n",
    "for op in orogeny_points:\n",
    "    if op.get_reconstructed_geometry():\n",
    "        all_op_points.extend(op.get_reconstructed_geometry().to_tessellated(np.radians(0.1)).to_lat_lon_list())\n",
    "prox_orogeny = me.points_proximity(x=[lon for lat,lon in all_op_points],\n",
    "                                   y=[lat for lat,lon in all_op_points],\n",
    "                                   spacing=sampling)\n",
    "\n",
    "\n",
    "# combine the rasters to isolate areas not too near to coastlines\n",
    "# and not too far from subduction zones\n",
    "m1 = prox_ocean.where((prox_ocean>min_distance_to_coastlines))\n",
    "m2 = prox_sz.where(prox_sz<max_distance_to_trenches)\n",
    "m2.data = m1.data+m2.data\n",
    "\n",
    "m2.data[np.isnan(m2.data)] = -999\n",
    "mountain_core = proximity(m2, target_values=[-999], distance_metric='GREAT_CIRCLE')\n",
    "\n",
    "\n",
    "\n",
    "m3 = prox_orogeny.where(prox_orogeny<max_distance_to_trenches)\n",
    "m3.data = m1.data+m3.data\n",
    "\n",
    "m3.data[np.isnan(m3.data)] = -999\n",
    "orogeny_core = proximity(m3, target_values=[-999], distance_metric='GREAT_CIRCLE')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "land = prox_ocean.where(prox_ocean==0, 1)\n",
    "\n",
    "topography = (mountain_core/200)+(land*200)+(orogeny_core/150)\n",
    "topography = topography.where(topography>0, np.nan)\n",
    "\n",
    "topography.plot()\n",
    "\n",
    "#orogeny_core.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b6ad28-406d-442a-baf0-49f2c24bfdb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#seafloor_depth.plot(vmin=-5000,vmax=3000)\n",
    "#topography.plot(vmin=-5000,vmax=3000)\n",
    "from gprm.utils import inpaint\n",
    "\n",
    "\n",
    "# recall that the coordinate names are inconsistent (x,y versus lat/lon)\n",
    "merge = seafloor_depth.copy(deep=True)\n",
    "merge.data = topography.data\n",
    "merge = merge.where(np.isfinite(merge), seafloor_depth)#.data[np.isnan(topography.data)] = seafloor_depth.data[np.isnan(topography.data)]\n",
    "\n",
    "#merge = pygmt.grdfill(merge, mode='s0.8', verbose='q')\n",
    "\n",
    "#bm = pygmt.grd2xyz(merge).dropna().reset_index(drop=True)\n",
    "#print('spherical interpolation step.....')\n",
    "#merge = pygmt.sphinterpolate(data=bm, spacing=final_grd_sampling, region='d', Q=0)\n",
    "\n",
    "#from rasterio.fill import fillnodata\n",
    "#merge.data = fillnodata(merge.data, mask=np.isnan(merge.data), smoothing_iterations=10) \n",
    "merge.data = inpaint.fill_ndimage(merge.data)\n",
    "\n",
    "\n",
    "trench_dist_max = 300e3\n",
    "trench_depth_max = 3000.\n",
    "subduction_trench = 1-(prox_sz-trench_dist_max)\n",
    "subduction_trench = (subduction_trench.where(subduction_trench>0, 0)/trench_dist_max)*trench_depth_max\n",
    "subduction_trench = subduction_trench.where(np.isnan(topography), 0)\n",
    "#subduction_trench.plot()\n",
    "\n",
    "merge.data = merge.data-subduction_trench\n",
    "#print(merge.shape)\n",
    "#print(subduction_trench.shape)\n",
    "\n",
    "merge.plot(cmap='viridis')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a2eb6-df76-4ce8-a5ea-1a8d794931eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pygplates\n",
    "from gprm.utils.deformation import topological_reconstruction\n",
    "\n",
    "DEFAULT_COLLISION = pygplates.ReconstructedGeometryTimeSpan.DefaultDeactivatePoints()\n",
    "\n",
    "anchor_plate_id = 0\n",
    "initial_time = 100\n",
    "youngest_time = 0\n",
    "time_increment = 1\n",
    "\n",
    "### make seamounts and LIPs??\n",
    "topological_model = pygplates.TopologicalModel(Atlantis.dynamic_polygons,\n",
    "                                               Atlantis.rotation_model,\n",
    "                                               anchor_plate_id=anchor_plate_id)\n",
    "\n",
    "hot_spot_points = {\n",
    "    'A':(10,-10), \n",
    "    'B':(-20,20), \n",
    "    'C':(10,40)\n",
    "}\n",
    "hot_spot_trail = {}\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "region = 'd'\n",
    "projection='W6i'\n",
    "reconstruction_model.polygon_snapshot('continents', 0).plot(fig, transparency=80, region=region, projection=projection, fill='darkkhaki')\n",
    "reconstruction_model.plate_snapshot(0).plot_boundaries(fig, region=region, projection=projection)\n",
    "\n",
    "#fig.plot(x=list(zip(*hot_spot_points))[1], y=list(zip(*hot_spot_points))[0], style='t0.2c', fill='red')\n",
    "fig.plot(x=[hot_spot_points[x][1] for x in hot_spot_points],\n",
    "         y=[hot_spot_points[x][0] for x in hot_spot_points], \n",
    "         style='t0.2c', fill='red')\n",
    "    \n",
    "#reconstruction_times = np.arange(100,-1,-10)\n",
    "for hot_spot_key in hot_spot_points:\n",
    "    rp = []\n",
    "    ra = []\n",
    "    reconstruction_times = np.sort(np.random.uniform(0, 200, size=25))\n",
    "    for reconstruction_time in reconstruction_times:\n",
    "\n",
    "        reconstructed_points = topological_model.reconstruct_geometry(\n",
    "            pygplates.PointOnSphere(hot_spot_points[hot_spot_key]),\n",
    "            initial_time=reconstruction_time,\n",
    "            oldest_time=200.,\n",
    "            youngest_time=0.,\n",
    "            time_increment=1)\n",
    "\n",
    "        #print(reconstruction_time, reconstructed_points.get_geometry_points(0.))\n",
    "        if reconstructed_points.get_geometry_points(0.):\n",
    "            rp.append(reconstructed_points.get_geometry_points(0.)[0].to_lat_lon())\n",
    "            ra.append(reconstruction_time)\n",
    "\n",
    "\n",
    "    lonlats = list(zip(*rp))\n",
    "    hot_spot_trail[hot_spot_key] = gpd.GeoDataFrame(data={'age': ra},\n",
    "                                          geometry=gpd.points_from_xy(lonlats[1], lonlats[0]), \n",
    "                                          crs=4326)\n",
    "    fig.plot(x=lonlats[1], y=lonlats[0], style='c0.1c')\n",
    "\n",
    "fig.basemap(frame='fg', region=region, projection=projection)\n",
    "fig.show(width=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16877736-84c5-4275-b64e-d2599362ba34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hot_spot_trail['A']\n",
    "import os\n",
    "import xarray as xr\n",
    "from ptt.utils.call_system_command import call_system_command\n",
    "\n",
    "for hot_spot_key in hot_spot_trail.keys():\n",
    "\n",
    "    d2sm = me.points_proximity(hot_spot_trail[hot_spot_key].geometry.x, \n",
    "                               hot_spot_trail[hot_spot_key].geometry.y, spacing=final_grd_sampling)\n",
    "    d2sm = d2sm.where(d2sm>100.,100.)\n",
    "    d2sm = (1./d2sm)\n",
    "\n",
    "\n",
    "    filter_length_km = 1000\n",
    "    #pygmt.grdfilter(tmp, filter='g{:f}k+h'.format(filter_length_km), \n",
    "    #                distance='2', coltypes='g').plot()\n",
    "    d2sm.to_netcdf('./_tmp.nc')\n",
    "    call_system_command(['gmt', 'grdfilter', '_tmp.nc', \n",
    "                         '-Fg{:f}k'.format(filter_length_km), '-D2', '-G_tmpp.nc', '-fg'])\n",
    "    seamounts = xr.open_dataarray('./_tmpp.nc')\n",
    "    os.remove('./_tmpp.nc')\n",
    "    #\"\"\"\n",
    "\n",
    "    seamounts = (seamounts/seamounts.data.max())*np.random.uniform(low=2000,high=3000,size=1)\n",
    "    seamounts = seamounts.where(merge<0, 0)\n",
    "    merge+=seamounts\n",
    "    \n",
    "#seamounts.plot()\n",
    "merge.plot(cmap='viridis', vmin=-8000, vmax=4000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85612b2b-fce7-4ab4-a4f6-ecb8e82c831a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "sys.path.append('../sphipple/')\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pygmt\n",
    "import ptt.utils.call_system_command as call_system_command\n",
    "import pyshtools\n",
    "\n",
    "from stipple_scalar_grids_spherical import quantize_grid, mach_banding, write_netcdf_grid\n",
    "\n",
    "def make_noise_grid(lmax=300, exponent=-2, scaling=1, spacing='6m'):\n",
    "    degrees = np.arange(lmax+1, dtype=float)\n",
    "    degrees[0] = np.inf\n",
    "\n",
    "    power_per_degree = degrees**(exponent)\n",
    "    power_per_degree[:200] = 0\n",
    "\n",
    "    noise = pyshtools.SHCoeffs.from_random(power_per_degree, seed=None).expand().to_xarray()\n",
    "\n",
    "    noise = pygmt.grdsample(noise, region='d', spacing=spacing)\n",
    "    return noise*scaling\n",
    "\n",
    "\n",
    "hp_filter_length_km = 500.\n",
    "lp_filter_length_km = 250.\n",
    "\n",
    "\n",
    "#agegrid = xr.open_dataarray('/Users/simon/Data/AgeGrids/2020/age.2020.1.GeeK2007.6m.nc')\n",
    "agegrid = pygmt.grdsample('../octopus/Atlantis2/masked/Atlantis2_seafloor_age_mask_0.0Ma.nc',\n",
    "                          region='d', spacing='{:f}d'.format(final_grd_sampling))\n",
    "#agegrid.data += make_noise_grid(lmax=400, scaling=2.).data\n",
    "\n",
    "\n",
    "quantized_raster = quantize_grid(agegrid, q=5.)\n",
    "\n",
    "quantized_raster.data += make_noise_grid(lmax=400, scaling=5., spacing='{:f}d'.format(final_grd_sampling)).data\n",
    "\n",
    "quantized_raster\n",
    "\n",
    "write_netcdf_grid('qraster.nc', agegrid.lon.data, agegrid.lat.data, quantized_raster)\n",
    "#filt_grid = pygmt.grdfilter(quantized_raster, \n",
    "#                            filter='g{:f}k+h'.format(filter_length_km), \n",
    "#                            distance='2', coltypes='g')\n",
    "\n",
    "call_system_command(['gmt', 'grdfilter', 'qraster.nc', \n",
    "                     '-Fg{:f}k+h'.format(hp_filter_length_km), '-D2', '-Gmach_banded_raster.nc', '-fg'])\n",
    "call_system_command(['gmt', 'grdfilter', 'mach_banded_raster.nc', \n",
    "                     '-Fg{:f}k'.format(lp_filter_length_km), '-D2', '-Gmach_banded_raster.nc', '-fg'])\n",
    "filt_grid = xr.open_dataarray('./mach_banded_raster.nc')\n",
    "os.remove('mach_banded_raster.nc')\n",
    "\n",
    "\n",
    "#filt_grid = filt_grid+make_noise_grid(scaling=2.)\n",
    "\n",
    "#fig,ax = plt.subplots(figsize=(20,10))\n",
    "#filt_grid.plot(vmin=-2,vmax=2, ax=ax)\n",
    "\n",
    "filt_grid = filt_grid.where(np.isfinite(filt_grid), 0)\n",
    "\n",
    "mergef = merge + filt_grid*300\n",
    "mergef.plot(vmin=-6000, vmax=4000)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(mergef.data[180,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b91a944-5949-4a46-9672-aa70a866c7c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Synthetic drill holes?\n",
    "\n",
    "\n",
    "### Present-day GPS velocity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cae541-699c-49f8-898a-19ea44289648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append('/Users/simon/GIT/vh0/notebooks/ModelGeneration/')\n",
    "import ocean_remanence_vectors as orv\n",
    "\n",
    "age_grid_filename = './Atlantis2/masked/Atlantis2_seafloor_age_mask_0.0Ma.nc'\n",
    "\n",
    "snapshot = Atlantis.plate_snapshot(0.)\n",
    "\n",
    "static_polygon_filename = './_tmp.shp'\n",
    "fc = pygplates.FeatureCollection([rt.get_resolved_feature() for rt in snapshot.resolved_topologies])\n",
    "fc.write(static_polygon_filename)\n",
    "\n",
    "grd_spacing = final_grd_sampling\n",
    "\n",
    "age_grid, plate_id_raster = orv.build_input_grids(age_grid_filename,\n",
    "                                                  static_polygon_filename,\n",
    "                                                  grd_spacing)\n",
    "\n",
    "(paleo_latitude,\n",
    " paleo_declination) = orv.reconstruct_agegrid_to_birthtime(\n",
    "    Atlantis, \n",
    "    age_grid, \n",
    "    plate_id_raster, \n",
    "    return_type='xarray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda8d5a-154b-4045-a25e-89034d1c7359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from remit.data.models import create_vim\n",
    "from remit.utils.grid import coeffs2map\n",
    "#from remit.utils.profile import polarity_timescale\n",
    "from remit.earthvim import SeafloorGrid, GlobalVIS, PolarityTimescale\n",
    "\n",
    "lmin = 16\n",
    "lmax = 500\n",
    "input_sampling = 0.1\n",
    "\n",
    "GPTS = PolarityTimescale(timescalefile='/Users/simon/Documents/2022IMAS-OUC_SOMG/PracFiles/Atlantis2/Atlantis_GPTS.txt')\n",
    "\n",
    "GK07 = {'seafloor_layer':'2d',\n",
    "        'layer_boundary_depths':[0,500,1500,6500], \n",
    "        'layer_weights':[5,2.3,1.2], \n",
    "        'MagMax':None, \n",
    "        'P':5, \n",
    "        'lmbda':3, \n",
    "        'Mtrm':1, \n",
    "        'Mcrm':0,\n",
    "        'PolarityTimescale':GPTS}\n",
    "\n",
    "\n",
    "ocean = SeafloorGrid.from_xarray(age_grid, paleo_declination, paleo_latitude)\n",
    "ocean.resample(shape=(1801,3601))\n",
    "\n",
    "layer_params = GK07.copy()\n",
    "\n",
    "vis = GlobalVIS.from_random(exponent=-1.5, scaling=0.1)\n",
    "vis.resample(shape=(1801,3601))\n",
    "\n",
    "#ocean.lon\n",
    "totalvim = create_vim(ocean, vis, **layer_params)\n",
    "\n",
    "totalvim.plot()\n",
    "#plt.pcolormesh(totalvim.mphi, vmin=-10000, vmax=10000)\n",
    "#plt.colorbar()\n",
    "#print(vis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed32b1-c91a-4d16-8f80-f6f3004b818c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from remit.utils.grid import shmaggrid2tmi\n",
    "\n",
    "vsh, coeffs = totalvim.transform(lmax=lmax)\n",
    "\n",
    "# Need to make this into xarray\n",
    "tmi = shmaggrid2tmi(coeffs.expand())\n",
    "\n",
    "#mp = coeffs2map(coeffs, altitude=80000, lmax=lmax, lmin=lmin)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(20,10))\n",
    "mp.plot(cmap='seismic', colorbar='right', ax=ax, cmap_limits=(-100,100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f47d922-5032-4ec8-b5e8-62549196c20e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append('/Users/simon/GIT/pgpslabs/')\n",
    "import slab_tracker_utils as slab\n",
    "\n",
    "topology_features = Atlantis.dynamic_polygons\n",
    "rotation_model = Atlantis.rotation_model\n",
    "start_time = 40.\n",
    "end_time = 0.\n",
    "time_step = 2.0\n",
    "dip_angle_degrees = 50.0\n",
    "line_tessellation_distance = np.radians(1.0)\n",
    "\n",
    "agegrid_filename = None\n",
    "\n",
    "subduction_boundary_sections = slab.getSubductionBoundarySections(\n",
    "    topology_features,\n",
    "    rotation_model,\n",
    "    0.)\n",
    "\n",
    "\n",
    "\n",
    "output_data = []\n",
    "dip_angle_radians = np.radians(dip_angle_degrees)\n",
    "time_list = np.arange(start_time,end_time-time_step,-time_step)\n",
    "\n",
    "\n",
    "for time in time_list:\n",
    "    \n",
    "    print('time %0.2f Ma' % time)\n",
    "    \n",
    "    # call function to get subduction boundary segments\n",
    "    subduction_boundary_sections = slab.getSubductionBoundarySections(topology_features,\n",
    "                                                                      rotation_model,\n",
    "                                                                      time)\n",
    "    \n",
    "    # Set up an age grid interpolator for this time, to be used\n",
    "    # for each tessellated line segment\n",
    "    #if agegrid_filename is not None:\n",
    "    #grdfile = '%s%d%s' % (agegrid_filename[0],time,agegrid_filename[1])\n",
    "    #grdfile = '../pgpslabs-Bec/agegrid_final_mask_0.grd'\n",
    "    grdfile = '../agegrid-0.1/grid_files/unmasked/M16_seafloor_age_0.0Ma.nc'\n",
    "    lut = slab.make_age_interpolator(grdfile)\n",
    "    \n",
    "    # Loop over each segment\n",
    "    for segment_index,subduction_segment in enumerate(subduction_boundary_sections):\n",
    "            \n",
    "        # find the overrding plate id (and only continue if we find it)\n",
    "        overriding_and_subducting_plates = slab.find_overriding_and_subducting_plates(subduction_segment,time)\n",
    "                \n",
    "        if not overriding_and_subducting_plates:\n",
    "            continue\n",
    "        overriding_plate, subducting_plate, subduction_polarity = overriding_and_subducting_plates\n",
    "\n",
    "        overriding_plate_id = overriding_plate.get_resolved_feature().get_reconstruction_plate_id()\n",
    "        subducting_plate_id = subducting_plate.get_resolved_feature().get_reconstruction_plate_id()\n",
    "        \n",
    "        subducting_plate_disappearance_time = -1.\n",
    "\n",
    "        tessellated_line = subduction_segment.get_resolved_geometry().to_tessellated(line_tessellation_distance)\n",
    "\n",
    "        #print len(tessellated_line.get_points())\n",
    "        \n",
    "        if agegrid_filename is not None:\n",
    "            x = tessellated_line.to_lat_lon_array()[:,1]\n",
    "            y = tessellated_line.to_lat_lon_array()[:,0]\n",
    "            subduction_ages = lut.ev(np.radians(y+90.),np.radians(x+180.))\n",
    "        else:\n",
    "            # if no age grids, just fill the ages with zero\n",
    "            subduction_ages = [0. for point in tessellated_line.to_lat_lon_array()[:,1]]\n",
    "              \n",
    "        # CALL THE MAIN WARPING FUNCTION\n",
    "        (points, \n",
    "         point_depths, \n",
    "         polyline) = slab.warp_subduction_segment(tessellated_line,\n",
    "                                                  rotation_model,\n",
    "                                                  subducting_plate_id,\n",
    "                                                  overriding_plate_id,\n",
    "                                                  subduction_polarity,\n",
    "                                                  time,\n",
    "                                                  end_time,\n",
    "                                                  time_step,\n",
    "                                                  dip_angle_radians,\n",
    "                                                  subducting_plate_disappearance_time)\n",
    "        \n",
    "        output_data.append(gpd.GeoDataFrame(\n",
    "            data={'subduction_time':np.ones(len(point_depths)).T*time,\n",
    "                  'depth': point_depths,\n",
    "                  'age_at_subduction': subduction_ages},\n",
    "            geometry=gpd.points_from_xy(polyline.to_lat_lon_array()[:,1], \n",
    "                                        polyline.to_lat_lon_array()[:,0]), \n",
    "            crs=4326))\n",
    "        \n",
    "present_day_slab = gpd.GeoDataFrame(\n",
    "    gpd.pd.concat(output_data, ignore_index=True), crs=output_data[0].crs)\n",
    "slab_earthquakes = present_day_slab.sample(200)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,11))\n",
    "ax = fig.add_subplot(111)\n",
    "cm = ax.scatter(slab_earthquakes.geometry.x, \n",
    "                slab_earthquakes.geometry.y, \n",
    "                c=slab_earthquakes.depth, \n",
    "                s=50,\n",
    "                cmap='magma_r', vmin=0., vmax=450)\n",
    "ax.set_aspect('equal')\n",
    "fig.colorbar(cm)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1c0b6b-fe35-4595-8f0b-af07f74da298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pygmt.grdfilter(mergef, filter='g{:f}k'.format(700), \n",
    "                distance='2', coltypes='g').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa68d0c-be44-4cb4-8d6c-a77524a98a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "def create_gaussian_kernel(size, sigma):\n",
    "    \"\"\"Create a 2D Gaussian kernel.\"\"\"\n",
    "    k = (size - 1) // 2\n",
    "    x, y = np.mgrid[-k:k+1, -k:k+1]\n",
    "    g = np.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
    "    return g / g.sum()\n",
    "\n",
    "def apply_spatially_varying_smoothing(smoothing_array, data_array):\n",
    "    \"\"\"Apply spatially varying smoothing to the data_array based on smoothing_array.\"\"\"\n",
    "    smoothed_array = np.zeros_like(data_array)\n",
    "    rows, cols = data_array.shape\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            # Determine the kernel size and sigma based on the smoothing factor\n",
    "            smoothing_factor = smoothing_array[i, j]\n",
    "            #kernel_size = max(3, int(smoothing_factor) * 2 + 1)  # Ensure kernel size is at least 3\n",
    "            kernel_size = 7\n",
    "            sigma = smoothing_factor\n",
    "            \n",
    "            # Create the Gaussian kernel\n",
    "            kernel = create_gaussian_kernel(kernel_size, sigma)\n",
    "            \n",
    "            # Determine the region to apply the kernel\n",
    "            half_k = kernel_size // 2\n",
    "            i_min = max(i - half_k, 0)\n",
    "            i_max = min(i + half_k + 1, rows)\n",
    "            j_min = max(j - half_k, 0)\n",
    "            j_max = min(j + half_k + 1, cols)\n",
    "            \n",
    "            # Extract the region and apply the convolution\n",
    "            region = data_array[i_min:i_max, j_min:j_max]\n",
    "            k_i_min = max(half_k - i, 0)\n",
    "            k_i_max = min(half_k + (rows - i), kernel_size)\n",
    "            k_j_min = max(half_k - j, 0)\n",
    "            k_j_max = min(half_k + (cols - j), kernel_size)\n",
    "            region_kernel = kernel[k_i_min:k_i_max, k_j_min:k_j_max]\n",
    "            \n",
    "            # Apply convolution to the region and assign the result to the center cell\n",
    "            if region.size > 0:\n",
    "                smoothed_value = np.sum(region * region_kernel)\n",
    "                smoothed_array[i, j] = smoothed_value\n",
    "    \n",
    "    return smoothed_array\n",
    "\n",
    "\n",
    "\n",
    "smoothing_array = inpaint.fill_ndimage(seafloor_age.data)\n",
    "smoothing_array[smoothing_array<2] = 2\n",
    "smoothing_array[smoothing_array>120] = 120\n",
    "smoothing_array = np.sqrt(smoothing_array)/2\n",
    "data_array = mergef.data\n",
    "\n",
    "smoothed_array = apply_spatially_varying_smoothing(smoothing_array, data_array)\n",
    "print(smoothed_array)\n",
    "\n",
    "# Add seamounts afterwards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee12c1-2321-4d1f-a265-0bbb4cc4c28f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(smoothed_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184286f-4396-4f4a-9d9c-b9c49d38d53f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(smoothed_array-data_array, vmin=0, vmax=1000)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85087148-defe-449f-8961-938ff07e93ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(smoothing_array)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d399076-4a0a-4225-b413-76bec7fc4191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(create_gaussian_kernel(5, .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62427843-806f-4ee6-bac8-f7a6b6ca489a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pygmt10]",
   "language": "python",
   "name": "conda-env-pygmt10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
